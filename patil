{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb52699d",
   "metadata": {},
   "source": [
    "DFS recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36525a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_graph_from_csv(csv_path):\n",
    "    graphNodes = pd.read_csv(csv_path)\n",
    "    graph = {}\n",
    "    for _, row in graphNodes.iterrows():\n",
    "        node = int(row['nodes'])\n",
    "        neighbours = row[1:].dropna().tolist()\n",
    "        graph[node] = [int(neighbour) for neighbour in neighbours]\n",
    "    return graph\n",
    "\n",
    "def dfs_recursive(graph, start, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "        \n",
    "    visited.add(start)\n",
    "    dfs_order = [start]\n",
    "    \n",
    "    for neighbour in graph.get(start, []):\n",
    "        if neighbour not in visited:\n",
    "            dfs_order.extend(dfs_recursive(graph, neighbour, visited))\n",
    "    \n",
    "    return dfs_order\n",
    "\n",
    "# Main execution\n",
    "graph = create_graph_from_csv(r\"graphNodes.csv\")\n",
    "\n",
    "start_node = int(input(\"Enter start node: \"))\n",
    "traversal_order = dfs_recursive(graph, start_node)\n",
    "print(\"DFS recursive:\", traversal_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d73885",
   "metadata": {},
   "source": [
    "DFS Non-recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e9686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS non recursive [3, 4, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "def graph_from_user():\n",
    "    graph = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # edges for each node\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        edges = input(f\"Enter space-separated neighbors for node {node}: \"). strip()\n",
    "        \n",
    "        if edges:\n",
    "            neighbours = [int(x) for x in edges.split()]\n",
    "            graph[node] = neighbours\n",
    "            \n",
    "            # reverse edges\n",
    "            for neighbour in neighbours:\n",
    "                if neighbour not in graph:\n",
    "                    graph[neighbour] = [node] #[] are all lists\n",
    "                    \n",
    "                else:\n",
    "                    if node not in graph[neighbour]:\n",
    "                        graph[neighbour].append(node)\n",
    "        \n",
    "        else:\n",
    "            graph[node] = []\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def dfs_non_recursive(graph, start):\n",
    "    \n",
    "    visited = set() # empty set to keep track of visited nodes\n",
    "    \n",
    "    stack = [start] # list acting as stack to track nodes we need to visit.\n",
    "    \n",
    "    dfs_order = [] # empty list to keep track of traversal order\n",
    "    \n",
    "    while stack: # runs while stack ain't empty\n",
    "        node = stack.pop()\n",
    "        \n",
    "        if node not in visited:  # starts with the \"start\" node\n",
    "            visited.add(node)\n",
    "            dfs_order.append(node)\n",
    "            \n",
    "            for neighbour in graph.get(node, []): # get all the neighbours of current node\n",
    "                if neighbour not in visited:\n",
    "                    stack.append(neighbour) # add each unvisited neighbour to stack \n",
    "                    \n",
    "    return dfs_order \n",
    "                \n",
    "graph = graph_from_user()   \n",
    "\n",
    "start_node = int(input(\"Enter start node: \"))\n",
    "\n",
    "traversal_order = dfs_non_recursive(graph, start_node)     \n",
    "\n",
    "print(\"DFS non recursive\", traversal_order)  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9d193",
   "metadata": {},
   "source": [
    "Breadth first search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import deque\n",
    "\n",
    "def graph_from_user():\n",
    "    graph = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # edges for each node\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        edges = input(f\"Enter space-separated neighbors for node {node}: \"). strip()\n",
    "        \n",
    "        if edges:\n",
    "            neighbours = [int(x) for x in edges.split()]\n",
    "            graph[node] = neighbours\n",
    "            \n",
    "            # reverse edges\n",
    "            for neighbour in neighbours:\n",
    "                if neighbour not in graph:\n",
    "                    graph[neighbour] = [node] #[] are all lists\n",
    "                    \n",
    "                else:\n",
    "                    if node not in graph[neighbour]:\n",
    "                        graph[neighbour].append(node)\n",
    "        \n",
    "        else:\n",
    "            graph[node] = []\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def bfs(graph, start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    bfs_traversal_list = []\n",
    "    \n",
    "    visited.add(start)\n",
    "    \n",
    "    while queue:\n",
    "        current_node = queue.popleft()\n",
    "        bfs_traversal_list.append(current_node)\n",
    "        \n",
    "        for neighbour in graph.get(current_node, []):\n",
    "            if neighbour not in visited:\n",
    "                visited.add(neighbour)\n",
    "                queue.append(neighbour)\n",
    "                \n",
    "    return bfs_traversal_list\n",
    "\n",
    "\n",
    "graph = graph_from_user()\n",
    "start_node = int(input(\"Enter start node for BFS: \"))\n",
    "travel_order = bfs(graph, start_node)\n",
    "print(travel_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775b9ce",
   "metadata": {},
   "source": [
    "Best first search directed unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # heuristic values for each node\n",
    "    print(\"\\nEnter heuristic values for each node:\")\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "        \n",
    "    #edges for each node\n",
    "    print(\"\\nEnter neighbors for each node:\")\n",
    "    for node in range(1, num_nodes+1):\n",
    "        edges = input(f\"Enter space-separated neighbors for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "            neighbours = [int(x) for x in edges.split()]\n",
    "            graph[node] = neighbours\n",
    "        else:\n",
    "            graph[node] = []\n",
    "            \n",
    "    return graph, heuristic\n",
    "\n",
    "def best_first_search(graph, heuristic, start, goal):\n",
    "    \n",
    "    visited = set()\n",
    "    path = []\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristic[start], start)) # Lower heuristic values have higher priority\n",
    "    \n",
    "    while not pq.empty():\n",
    "        _, current = pq.get()\n",
    "        \n",
    "        if current not in visited:\n",
    "            visited.add(current)\n",
    "            path.append(current)\n",
    "            \n",
    "            if current == goal:\n",
    "                return path\n",
    "            \n",
    "            for neighbour in graph.get(current, []):\n",
    "                if neighbour not in visited:\n",
    "                    pq.put((heuristic[neighbour], neighbour))\n",
    "    \n",
    "    return None\n",
    "\n",
    "graph, heuristic = get_graph_and_heuristics()\n",
    "start_node = int(input(\"\\nEnter start node: \"))\n",
    "goal_node = int(input(\"Enter goal node: \"))\n",
    "\n",
    "path = best_first_search(graph, heuristic, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"\\nPath found:\", path)\n",
    "else:\n",
    "    print(\"\\nNo path found to goal\")\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65194ee8",
   "metadata": {},
   "source": [
    "Best first search undirected unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873775ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    print(\"\\nEnter heuristics for each node: \")\n",
    "    for node in range(1, num_nodes+1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "    \n",
    "    print(\"\\nEnter neighbors for each node:\")\n",
    "    for node in range(1, num_nodes+1):\n",
    "        edges = input(f\"Enter space-separated neighbors for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "            neighbours = [int(x) for x in edges.split()]\n",
    "            graph[node] = neighbours\n",
    "            \n",
    "            for neighbour in neighbours:\n",
    "                if neighbour not in graph:\n",
    "                    graph[neighbour] = [node]\n",
    "                    \n",
    "                else:\n",
    "                    if node not in graph[neighbour]:\n",
    "                        graph[neighbour].append(node)\n",
    "                        \n",
    "        else:\n",
    "            graph[node] = []\n",
    "            \n",
    "    return graph, heuristic\n",
    "\n",
    "def best_first_search(graph, heuristic, start, goal):\n",
    "    visited = set()\n",
    "    path = []\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristic[start], start))\n",
    "    \n",
    "    while not pq.empty():\n",
    "        _, current = pq.get()\n",
    "        \n",
    "        if current not in visited:   \n",
    "            visited.add(current)\n",
    "            path.append(current)\n",
    "            \n",
    "            if current == goal:\n",
    "                return path\n",
    "        \n",
    "            for neighbour in graph.get(current, []):\n",
    "                if neighbour not in visited:\n",
    "                    pq.put((heuristic[neighbour], neighbour))\n",
    "    \n",
    "    return None\n",
    "\n",
    "graph, heuristic = get_graph_and_heuristics()\n",
    "start_node = int(input(\"\\nEnter start node: \"))\n",
    "goal_node = int(input(\"Enter goal node: \"))\n",
    "\n",
    "path = best_first_search(graph, heuristic, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"\\nPath found:\", path)\n",
    "else:\n",
    "    print(\"\\nNo path found to goal\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad08f63",
   "metadata": {},
   "source": [
    "Best first search undirected weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d86fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}  # Will store {node: [(neighbor, weight), ...]}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # Get heuristic values\n",
    "    print(\"\\nEnter heuristic values for each node:\")\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "        \n",
    "    # Get edges and weights\n",
    "    print(\"\\nFor each node, enter neighbors and weights\")\n",
    "    print(\"Format: neighbor1 weight1 neighbor2 weight2 ... (space-separated)\")\n",
    "    \n",
    "    for node in range(1, num_nodes+1):\n",
    "        edges = input(f\"Enter neighbors and weights for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "           values = edges.split()\n",
    "           neighbour_with_weights = []\n",
    "           \n",
    "           for i in range(0, len(values), 2):\n",
    "               neighbour = int(values[i])\n",
    "               weight = float(values[i+1])\n",
    "               neighbour_with_weights.append((neighbour, weight))    \n",
    "           graph[node] = neighbour_with_weights\n",
    "           \n",
    "           for neighbour, weight in neighbour_with_weights:\n",
    "               if neighbour not in graph:\n",
    "                   graph[neighbour] = [(node, weight)]\n",
    "                   \n",
    "               else:\n",
    "                   if not any(node==n for n, w in graph[neighbour]):\n",
    "                       graph[neighbour].append((node, weight))\n",
    "                       \n",
    "        else:\n",
    "            graph[node] = []\n",
    "        \n",
    "    return graph, heuristic\n",
    "\n",
    "def best_first_search(graph, heuristic, start, goal):\n",
    "    visited = set()\n",
    "    path = []\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristic[start], start))\n",
    "    \n",
    "    while not pq.empty():\n",
    "        _,current = pq.get()\n",
    "        \n",
    "        if current not in visited:\n",
    "            visited.add(current)\n",
    "            path.append(current)\n",
    "            \n",
    "            if current == goal:\n",
    "                return path\n",
    "            \n",
    "            for neighbour, weight in graph.get(current, []):\n",
    "                if neighbour not in visited:\n",
    "                    pq.put((heuristic[neighbour], neighbour))\n",
    "    return None\n",
    "\n",
    "graph, heuristic = get_graph_and_heuristics()\n",
    "start_node = int(input(\"\\nEnter start node: \"))\n",
    "goal_node = int(input(\"Enter goal node: \"))\n",
    "\n",
    "path = best_first_search(graph, heuristic, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"\\nPath found:\", path)\n",
    "else:\n",
    "    print(\"\\nNo path found to goal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b393f",
   "metadata": {},
   "source": [
    "Best first search directed weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}  # Will store {node: [(neighbor, weight), ...]}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # Get heuristic values\n",
    "    print(\"\\nEnter heuristic values for each node:\")\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "        \n",
    "    # Get edges and weights\n",
    "    print(\"\\nFor each node, enter neighbors and weights\")\n",
    "    print(\"Format: neighbor1 weight1 neighbor2 weight2 ... (space-separated)\")\n",
    "    \n",
    "    for node in range(1, num_nodes+1):\n",
    "        edges = input(f\"Enter neighbors and weights for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "           values = edges.split()\n",
    "           neighbour_with_weights = []\n",
    "           \n",
    "           for i in range(0, len(values), 2):\n",
    "               neighbour = int(values[i])\n",
    "               weight = float(values[i+1])\n",
    "               neighbour_with_weights.append((neighbour, weight))    \n",
    "           graph[node] = neighbour_with_weights\n",
    "                       \n",
    "        else:\n",
    "            graph[node] = []\n",
    "        \n",
    "    return graph, heuristic\n",
    "\n",
    "def best_first_search(graph, heuristic, start, goal):\n",
    "    visited = set()\n",
    "    path = []\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((heuristic[start], start))\n",
    "    \n",
    "    while not pq.empty():\n",
    "        _,current = pq.get()\n",
    "        \n",
    "        if current not in visited:\n",
    "            visited.add(current)\n",
    "            path.append(current)\n",
    "            \n",
    "            if current == goal:\n",
    "                return path\n",
    "            \n",
    "            for neighbour, weight in graph.get(current, []):\n",
    "                if neighbour not in visited:\n",
    "                    pq.put((heuristic[neighbour], neighbour))\n",
    "    return None\n",
    "\n",
    "graph, heuristic = get_graph_and_heuristics()\n",
    "start_node = int(input(\"\\nEnter start node: \"))\n",
    "goal_node = int(input(\"Enter goal node: \"))\n",
    "\n",
    "path = best_first_search(graph, heuristic, start_node, goal_node)\n",
    "\n",
    "if path:\n",
    "    print(\"\\nPath found:\", path)\n",
    "else:\n",
    "    print(\"\\nNo path found to goal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c5e9a",
   "metadata": {},
   "source": [
    "A* algorithm, directed weighted graph and heuristic values from a .csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics(graph_file, heuristic_file):\n",
    "    # Read graph from CSV\n",
    "    graph_df = pd.read_csv(graph_file)\n",
    "    graph = {}\n",
    "    \n",
    "    for _, row in graph_df.iterrows():\n",
    "        source = int(row['source'])\n",
    "        target = int(row['target'])\n",
    "        weight = float(row['weight'])\n",
    "        \n",
    "        if source not in graph:\n",
    "            graph[source] = []\n",
    "        graph[source].append((target, weight))\n",
    "    \n",
    "    # Read heuristics from CSV\n",
    "    # Expected format: node,heuristic\n",
    "    heuristic_df = pd.read_csv(heuristic_file)\n",
    "    heuristic = {int(row['node']): float(row['heuristic']) \n",
    "                 for _, row in heuristic_df.iterrows()}\n",
    "    \n",
    "    return graph, heuristic\n",
    "\n",
    "def astar(graph, heuristic, start, goal):\n",
    "    # Priority queue for open nodes: (f_score, node)\n",
    "    open_set = PriorityQueue()\n",
    "    open_set.put((0 + heuristic[start], start))\n",
    "    \n",
    "    # Keep track of g_scores (cost from start to node)\n",
    "    g_score = {start: 0}\n",
    "    \n",
    "    # Keep track of where we came from\n",
    "    came_from = {}\n",
    "    \n",
    "    while not open_set.empty():\n",
    "        # Get node with lowest f_score\n",
    "        current_f, current = open_set.get()\n",
    "        \n",
    "        # If we reached the goal, reconstruct and return the path\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            return path[::-1]  # Reverse path to get start->goal\n",
    "        \n",
    "        # Check all neighbors\n",
    "        for neighbor, weight in graph.get(current, []):\n",
    "            # Calculate tentative g_score\n",
    "            tentative_g = g_score[current] + weight\n",
    "            \n",
    "            # If we found a better path to neighbor\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristic[neighbor]\n",
    "                open_set.put((f_score, neighbor))\n",
    "    \n",
    "    return None  # No path found\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    graph, heuristic = read_graph_and_heuristics(r\"A_star_graph.csv\", r\"A_star_heuristic.csv\")\n",
    "    \n",
    "    start_node = int(input(\"Enter start node: \"))\n",
    "    goal_node = int(input(\"Enter goal node: \"))\n",
    "    \n",
    "    path = astar(graph, heuristic, start_node, goal_node)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\nPath found:\", path)\n",
    "        \n",
    "        # Calculate total cost\n",
    "        total_cost = 0\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            next_node = path[i+1]\n",
    "            for neighbor, weight in graph[current]:\n",
    "                if neighbor == next_node:\n",
    "                    total_cost += weight\n",
    "                    break\n",
    "        print(\"Total cost:\", total_cost)\n",
    "    else:\n",
    "        print(\"\\nNo path found to goal\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Required CSV files not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e2a90",
   "metadata": {},
   "source": [
    "9. Implement A* algorithm. Read directed weighted graph and heuristic values from user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}  # Will store {node: [(neighbor, weight), ...]}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # Get heuristic values\n",
    "    print(\"\\nEnter heuristic values for each node:\")\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "    \n",
    "    # Get edges and weights\n",
    "    print(\"\\nFor each node, enter neighbors and weights\")\n",
    "    print(\"Format: neighbor1 weight1 neighbor2 weight2 ... (space-separated)\")\n",
    "    \n",
    "    for node in range(1, num_nodes + 1):\n",
    "        edges = input(f\"Enter neighbors and weights for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "            values = edges.split()\n",
    "            neighbour_with_weights = []\n",
    "            \n",
    "            for i in range(0, len(values), 2):\n",
    "                neighbour = int(values[i])\n",
    "                weight = float(values[i + 1])\n",
    "                neighbour_with_weights.append((neighbour, weight))\n",
    "            graph[node] = neighbour_with_weights\n",
    "        else:\n",
    "            graph[node] = []\n",
    "            \n",
    "    return graph, heuristic\n",
    "\n",
    "def astar(graph, heuristic, start, goal):\n",
    "    # Priority queue for open nodes: (f_score, node)\n",
    "    open_set = PriorityQueue()\n",
    "    open_set.put((0 + heuristic[start], start))\n",
    "    \n",
    "    # Keep track of g_scores (cost from start to node)\n",
    "    g_score = {start: 0}\n",
    "    \n",
    "    # Keep track of where we came from\n",
    "    came_from = {}\n",
    "    \n",
    "    while not open_set.empty():\n",
    "        # Get node with lowest f_score\n",
    "        current_f, current = open_set.get()\n",
    "        \n",
    "        # If we reached the goal, reconstruct and return the path\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            return path[::-1]  # Reverse path to get start->goal\n",
    "        \n",
    "        # Check all neighbors\n",
    "        for neighbor, weight in graph.get(current, []):\n",
    "            # Calculate tentative g_score\n",
    "            tentative_g = g_score[current] + weight\n",
    "            \n",
    "            # If we found a better path to neighbor\n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristic[neighbor]\n",
    "                open_set.put((f_score, neighbor))\n",
    "    \n",
    "    return None  # No path found\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    # Get graph and heuristic values from user\n",
    "    graph, heuristic = get_graph_and_heuristics()\n",
    "    \n",
    "    start_node = int(input(\"\\nEnter start node: \"))\n",
    "    goal_node = int(input(\"Enter goal node: \"))\n",
    "    \n",
    "    path = astar(graph, heuristic, start_node, goal_node)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\nPath found:\", path)\n",
    "        \n",
    "        # Calculate total cost\n",
    "        total_cost = 0\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            next_node = path[i+1]\n",
    "            for neighbor, weight in graph[current]:\n",
    "                if neighbor == next_node:\n",
    "                    total_cost += weight\n",
    "                    break\n",
    "        print(\"Total cost:\", total_cost)\n",
    "    else:\n",
    "        print(\"\\nNo path found to goal\")\n",
    "        \n",
    "except ValueError as e:\n",
    "    print(f\"Error: Please enter valid numeric values\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cef61",
   "metadata": {},
   "source": [
    "10. Implement A* algorithm. Read undirected weighted graph and heuristic values from a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def read_graph_and_heuristics(graph_file, heuristic_file):\n",
    "    # Read graph from CSV\n",
    "    graph_df = pd.read_csv(graph_file)\n",
    "    graph = {}\n",
    "    \n",
    "    # Create undirected graph\n",
    "    for _, row in graph_df.iterrows():\n",
    "        source = int(row['source'])\n",
    "        target = int(row['target'])\n",
    "        weight = float(row['weight'])\n",
    "        \n",
    "        # Add edge source -> target\n",
    "        if source not in graph:\n",
    "            graph[source] = []\n",
    "        graph[source].append((target, weight))\n",
    "        \n",
    "        # Add edge target -> source (since undirected)\n",
    "        if target not in graph:\n",
    "            graph[target] = []\n",
    "        graph[target].append((source, weight))\n",
    "    \n",
    "    # Read heuristics from CSV\n",
    "    heuristic_df = pd.read_csv(heuristic_file)\n",
    "    heuristic = {int(row['node']): float(row['heuristic']) \n",
    "                for _, row in heuristic_df.iterrows()}\n",
    "    \n",
    "    return graph, heuristic\n",
    "\n",
    "def astar(graph, heuristic, start, goal):\n",
    "    open_set = PriorityQueue()\n",
    "    open_set.put((0 + heuristic[start], start))\n",
    "    \n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    \n",
    "    while not open_set.empty():\n",
    "        current_f, current = open_set.get()\n",
    "        \n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        \n",
    "        for neighbor, weight in graph.get(current, []):\n",
    "            tentative_g = g_score[current] + weight\n",
    "            \n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristic[neighbor]\n",
    "                open_set.put((f_score, neighbor))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    graph, heuristic = read_graph_and_heuristics(r\"A_star_graph.csv\", r\"A_star_heuristic.csv\")\n",
    "    \n",
    "    start_node = int(input(\"Enter start node: \"))\n",
    "    goal_node = int(input(\"Enter goal node: \"))\n",
    "    \n",
    "    path = astar(graph, heuristic, start_node, goal_node)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\nPath found:\", path)\n",
    "        \n",
    "        # Calculate total cost\n",
    "        total_cost = 0\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            next_node = path[i+1]\n",
    "            for neighbor, weight in graph[current]:\n",
    "                if neighbor == next_node:\n",
    "                    total_cost += weight\n",
    "                    break\n",
    "        print(\"Total cost:\", total_cost)\n",
    "    else:\n",
    "        print(\"\\nNo path found to goal\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Required CSV files not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f3bea",
   "metadata": {},
   "source": [
    "11. Implement A* algorithm. Read undirected weighted graph and heuristic values from user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def get_graph_and_heuristics():\n",
    "    graph = {}  # Will store {node: [(neighbor, weight), ...]}\n",
    "    heuristic = {}\n",
    "    \n",
    "    num_nodes = int(input(\"Enter number of nodes: \"))\n",
    "    \n",
    "    # Get heuristic values\n",
    "    print(\"\\nEnter heuristic values for each node:\")\n",
    "    for node in range(1, num_nodes + 1):\n",
    "        h_value = float(input(f\"Enter heuristic value for node {node}: \"))\n",
    "        heuristic[node] = h_value\n",
    "    \n",
    "    # Get edges and weights\n",
    "    print(\"\\nFor each node, enter neighbors and weights\")\n",
    "    print(\"Format: neighbor1 weight1 neighbor2 weight2 ... (space-separated)\")\n",
    "    \n",
    "    for node in range(1, num_nodes + 1):\n",
    "        edges = input(f\"Enter neighbors and weights for node {node}: \").strip()\n",
    "        \n",
    "        if edges:\n",
    "            values = edges.split()\n",
    "            neighbour_with_weights = []\n",
    "            \n",
    "            for i in range(0, len(values), 2):\n",
    "                neighbour = int(values[i])\n",
    "                weight = float(values[i + 1])\n",
    "                neighbour_with_weights.append((neighbour, weight))\n",
    "            \n",
    "            graph[node] = neighbour_with_weights\n",
    "            \n",
    "            # Add reverse edges (since undirected)\n",
    "            for neighbour, weight in neighbour_with_weights:\n",
    "                if neighbour not in graph:\n",
    "                    graph[neighbour] = [(node, weight)]\n",
    "                else:\n",
    "                    if not any(node == n for n, w in graph[neighbour]):\n",
    "                        graph[neighbour].append((node, weight))\n",
    "        else:\n",
    "            graph[node] = []\n",
    "            \n",
    "    return graph, heuristic\n",
    "\n",
    "def astar(graph, heuristic, start, goal):\n",
    "    open_set = PriorityQueue()\n",
    "    open_set.put((0 + heuristic[start], start))\n",
    "    \n",
    "    g_score = {start: 0}\n",
    "    came_from = {}\n",
    "    \n",
    "    while not open_set.empty():\n",
    "        current_f, current = open_set.get()\n",
    "        \n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "        \n",
    "        for neighbor, weight in graph.get(current, []):\n",
    "            tentative_g = g_score[current] + weight\n",
    "            \n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score = tentative_g + heuristic[neighbor]\n",
    "                open_set.put((f_score, neighbor))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    graph, heuristic = get_graph_and_heuristics()\n",
    "    \n",
    "    start_node = int(input(\"\\nEnter start node: \"))\n",
    "    goal_node = int(input(\"Enter goal node: \"))\n",
    "    \n",
    "    path = astar(graph, heuristic, start_node, goal_node)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\nPath found:\", path)\n",
    "        \n",
    "        # Calculate total cost\n",
    "        total_cost = 0\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            next_node = path[i+1]\n",
    "            for neighbor, weight in graph[current]:\n",
    "                if neighbor == next_node:\n",
    "                    total_cost += weight\n",
    "                    break\n",
    "        print(\"Total cost:\", total_cost)\n",
    "    else:\n",
    "        print(\"\\nNo path found to goal\")\n",
    "        \n",
    "except ValueError:\n",
    "    print(\"Error: Please enter valid numeric values\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af65a85",
   "metadata": {},
   "source": [
    "12. Implement Fuzzy set operations – union, intersection and complement. Demonstrate these operations with 3 fuzzy sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0514fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fuzzy_set(set_name): #Get fuzzy set from user with simplified input\n",
    "    print(f\"\\nEnter {set_name}:\")\n",
    "    elements = input(\"Enter elements (space-separated): \").split()\n",
    "    memberships = [float(x) for x in input(\"Enter membership values (0-1, space-separated): \").split()]\n",
    "    return dict(zip(elements, memberships))\n",
    "\n",
    "def fuzzy_union(set1, set2): # Union using max operator\n",
    "    union = {}\n",
    "    all_elements = set(set1) | set(set2)\n",
    "    for element in all_elements:\n",
    "        union[element] = max(set1.get(element, 0), set2.get(element, 0))\n",
    "    return union\n",
    "\n",
    "def fuzzy_intersection(set1, set2): # Intersection using min operator\n",
    "    intersection = {}\n",
    "    all_elements = set(set1) | set(set2)\n",
    "    for element in all_elements:\n",
    "        intersection[element] = min(set1.get(element, 0), set2.get(element, 0))\n",
    "    return intersection\n",
    "\n",
    "def fuzzy_complement(fuzzy_set): # Complement by subtracting from 1\n",
    "    return {element: 1-value for element, value in fuzzy_set.items()}\n",
    "\n",
    "# Get three fuzzy sets\n",
    "set_a = get_fuzzy_set(\"Set A\")\n",
    "set_b = get_fuzzy_set(\"Set B\")\n",
    "set_c = get_fuzzy_set(\"Set C\")\n",
    "\n",
    "# Perform and display operations\n",
    "print(\"\\nUnion Operations:\")\n",
    "print(\"A U B:\", fuzzy_union(set_a, set_b))\n",
    "print(\"B U C:\", fuzzy_union(set_b, set_c))\n",
    "print(\"A U C:\", fuzzy_union(set_a, set_c))\n",
    "\n",
    "print(\"\\nIntersection Operations:\")\n",
    "print(\"A ^ B:\", fuzzy_intersection(set_a, set_b))\n",
    "print(\"B ^ C:\", fuzzy_intersection(set_b, set_c))\n",
    "print(\"A ^ C:\", fuzzy_intersection(set_a, set_c))\n",
    "\n",
    "print(\"\\nComplement Operations:\")\n",
    "print(\"A':\", fuzzy_complement(set_a))\n",
    "print(\"B':\", fuzzy_complement(set_b))\n",
    "print(\"C':\", fuzzy_complement(set_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a892a8",
   "metadata": {},
   "source": [
    "13. Implement Fuzzy set operations – union, intersection and complement.\n",
    "Demonstrate De Morgan’s Law ( Complement of Union) with 2 fuzzy sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fuzzy_set(set_name):\n",
    "    print(f\"\\nEnter {set_name}:\")\n",
    "    elements = input(\"Enter elements (space-separated): \").split()\n",
    "    memberships = [float(x) for x in input(\"Enter membership values (0-1, space-separated): \").split()]\n",
    "    return dict(zip(elements, memberships))\n",
    "\n",
    "def fuzzy_union(set1, set2):\n",
    "    union = {}\n",
    "    all_elements = set(set1) | set(set2)\n",
    "    for element in all_elements:\n",
    "        union[element] = max(set1.get(element, 0), set2.get(element, 0))\n",
    "    return union\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    intersection = {}\n",
    "    all_elements = set(set1) | set(set2)\n",
    "    for element in all_elements:\n",
    "        intersection[element] = min(set1.get(element, 0), set2.get(element, 0))\n",
    "    return intersection\n",
    "\n",
    "def fuzzy_complement(fuzzy_set):\n",
    "    return {element: 1-value for element, value in fuzzy_set.items()}\n",
    "\n",
    "# Get two fuzzy sets\n",
    "set_a = get_fuzzy_set(\"Set A\")\n",
    "set_b = get_fuzzy_set(\"Set B\")\n",
    "\n",
    "# Calculate operations for De Morgan's Law\n",
    "union_ab = fuzzy_union(set_a, set_b)\n",
    "complement_union = fuzzy_complement(union_ab)\n",
    "\n",
    "complement_a = fuzzy_complement(set_a)\n",
    "complement_b = fuzzy_complement(set_b)\n",
    "intersection_complements = fuzzy_intersection(complement_a, complement_b)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDemonstrating De Morgan's Law:\")\n",
    "print(\"Complement of Union (A U B)':\", complement_union)\n",
    "print(\"Intersection of Complements (A' ^ B'):\", intersection_complements)\n",
    "print(\"\\nIf both results are equal, De Morgan's Law is verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906f20e",
   "metadata": {},
   "source": [
    "14. Implement Fuzzy set operations – union, intersection and complement.\n",
    "Demonstrate De Morgan’s Law ( Complement of Intersection) with 2 fuzzy sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fuzzy_set(set_name):\n",
    "    # Gets fuzzy set from user\n",
    "    # Returns dictionary with elements as keys and membership values (0-1) as values\n",
    "    print(f\"\\nEnter {set_name}:\")\n",
    "    elements = input(\"Enter elements (space-separated): \").split()\n",
    "    memberships = [float(x) for x in input(\"Enter membership values (0-1, space-separated): \").split()]\n",
    "    return dict(zip(elements, memberships))\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    # Finds intersection using min operator\n",
    "    # For each element, takes minimum of its membership values in both sets\n",
    "    intersection = {}\n",
    "    all_elements = set(set1) | set(set2)\n",
    "    for element in all_elements:\n",
    "        intersection[element] = min(set1.get(element, 0), set2.get(element, 0))\n",
    "    return intersection\n",
    "\n",
    "def fuzzy_union(set1, set2):\n",
    "    # Finds union using max operator\n",
    "    # For each element, takes maximum of its membership values in both sets\n",
    "    union = {}\n",
    "    all_elements = set(set1) | set(set2) \n",
    "    for element in all_elements:\n",
    "        union[element] = max(set1.get(element, 0), set2.get(element, 0))\n",
    "    return union\n",
    "\n",
    "def fuzzy_complement(fuzzy_set):\n",
    "    # Finds complement by subtracting membership value from 1\n",
    "    return {element: 1-value for element, value in fuzzy_set.items()}\n",
    "\n",
    "# Get two fuzzy sets from user\n",
    "set_a = get_fuzzy_set(\"Set A\")\n",
    "set_b = get_fuzzy_set(\"Set B\")\n",
    "\n",
    "# Calculate left side of De Morgan's Law: (A ∩ B)'\n",
    "intersection_ab = fuzzy_intersection(set_a, set_b)\n",
    "complement_intersection = fuzzy_complement(intersection_ab)\n",
    "\n",
    "# Calculate right side of De Morgan's Law: A' ∪ B'\n",
    "complement_a = fuzzy_complement(set_a)\n",
    "complement_b = fuzzy_complement(set_b)\n",
    "union_complements = fuzzy_union(complement_a, complement_b)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDemonstrating De Morgan's Law:\")\n",
    "print(\"Complement of Intersection (A ∩ B)':\", complement_intersection)\n",
    "print(\"Union of Complements (A' ∪ B'):\", union_complements)\n",
    "print(\"\\nIf both results are equal, De Morgan's Law is verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4859b",
   "metadata": {},
   "source": [
    "15. Implement Modified Tic-Tac-Toe using min-max algorithm such that in every round either computer wins or it is a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc10937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print('|'.join(row))\n",
    "    print()\n",
    "\n",
    "def is_moves_left(board):\n",
    "    return any(' ' in row for row in board)\n",
    "\n",
    "def evaluate(board):\n",
    "    lines = []\n",
    "    for row in board:\n",
    "        lines.extend([row[i:i+3] for i in range(len(row)-2)])\n",
    "\n",
    "    max_cols = max(len(row) for row in board)\n",
    "    for col in range(max_cols):\n",
    "        col_vals = [row[col] if col < len(row) else None for row in board]\n",
    "        lines.extend([col_vals[i:i+3] for i in range(len(col_vals)-2)])\n",
    "\n",
    "    diags = [\n",
    "        [board[0][0], board[1][1], board[2][2]] if len(board[0])>0 and len(board[1])>1 else [],\n",
    "        [board[0][1], board[1][2], board[2][1]] if len(board[0])>1 and len(board[1])>2 else [],\n",
    "        [board[0][2], board[1][1], board[2][0]] if len(board[0])>2 and len(board[1])>1 else [],\n",
    "        [board[0][3], board[1][2], board[2][1]] if len(board[0])>3 else []\n",
    "    ]\n",
    "    lines.extend(diags)\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line) == 3 and line[0] == line[1] == line[2] != ' ':\n",
    "            return 1 if line[0] == 'O' else -1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def minimax(board, is_max):\n",
    "    score = evaluate(board)\n",
    "    if score != 0 or not is_moves_left(board):\n",
    "        return score\n",
    "\n",
    "    best = -math.inf if is_max else math.inf\n",
    "\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[i])):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O' if is_max else 'X'\n",
    "                value = minimax(board, not is_max)\n",
    "                board[i][j] = ' '\n",
    "                best = max(best, value) if is_max else min(best, value)\n",
    "\n",
    "    return best\n",
    "\n",
    "def find_best_move(board):\n",
    "    best_val = -math.inf\n",
    "    best_move = (-1, -1)\n",
    "\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[i])):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O'\n",
    "                move_val = minimax(board, False)\n",
    "                board[i][j] = ' '\n",
    "                if move_val > best_val:\n",
    "                    best_val = move_val\n",
    "                    best_move = (i, j)\n",
    "    return best_move\n",
    "\n",
    "def is_valid_move(board, row, col):\n",
    "    return (0 <= row < len(board)) and (0 <= col < len(board[row])) and board[row][col] == ' '\n",
    "\n",
    "def main():\n",
    "    board = [[' ']*4, [' ']*3, [' ']*3]\n",
    "\n",
    "    print(\"You are X. Computer is O.\")\n",
    "    print(\"Computer plays first!\")\n",
    "\n",
    "    while True:\n",
    "        move = find_best_move(board)\n",
    "        if move != (-1, -1):\n",
    "            board[move[0]][move[1]] = 'O'\n",
    "        print_board(board)\n",
    "\n",
    "        if evaluate(board) == 1:\n",
    "            print(\"Computer wins!\")\n",
    "            break\n",
    "        if not is_moves_left(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                r, c = map(int, input(\"Enter your move (row col): \").split())\n",
    "                if is_valid_move(board, r, c):\n",
    "                    board[r][c] = 'X'\n",
    "                    break\n",
    "                print(\"Invalid move. Try again.\")\n",
    "            except:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "\n",
    "        print_board(board)\n",
    "\n",
    "        if evaluate(board) == -1:\n",
    "            print(\"You win! (should not happen)\")\n",
    "            break\n",
    "        if not is_moves_left(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3f5f9",
   "metadata": {},
   "source": [
    "16. Implement Modified Tic-Tac-Toe using min-max algorithm such that in every round either computer loses or it is a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print('|'.join(row))\n",
    "    print()\n",
    "\n",
    "def is_moves_left(board):\n",
    "    return any(' ' in row for row in board)\n",
    "\n",
    "def evaluate(board):\n",
    "    lines = []\n",
    "    for row in board:\n",
    "        lines.extend([row[i:i+3] for i in range(len(row)-2)])\n",
    "\n",
    "    max_cols = max(len(row) for row in board)\n",
    "    for col in range(max_cols):\n",
    "        col_vals = [row[col] if col < len(row) else None for row in board]\n",
    "        lines.extend([col_vals[i:i+3] for i in range(len(col_vals)-2)])\n",
    "\n",
    "    diags = [\n",
    "        [board[0][0], board[1][1], board[2][2]] if len(board[0])>0 and len(board[1])>1 else [],\n",
    "        [board[0][1], board[1][2], board[2][1]] if len(board[0])>1 and len(board[1])>2 else [],\n",
    "        [board[0][2], board[1][1], board[2][0]] if len(board[0])>2 and len(board[1])>1 else [],\n",
    "        [board[0][3], board[1][2], board[2][1]] if len(board[0])>3 else []\n",
    "    ]\n",
    "    lines.extend(diags)\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line) == 3 and line[0] == line[1] == line[2] != ' ':\n",
    "            return 1 if line[0] == 'O' else -1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def minimax(board, is_max):\n",
    "    score = evaluate(board)\n",
    "    if score != 0 or not is_moves_left(board):\n",
    "        return score\n",
    "\n",
    "    best = math.inf if is_max else -math.inf\n",
    "\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[i])):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O' if is_max else 'X'\n",
    "                value = minimax(board, not is_max)\n",
    "                board[i][j] = ' '\n",
    "                best = min(best, value) if is_max else max(best, value)\n",
    "\n",
    "    return best\n",
    "\n",
    "def find_best_move(board):\n",
    "    best_val = math.inf\n",
    "    best_move = (-1, -1)\n",
    "\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[i])):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O'\n",
    "                move_val = minimax(board, False)\n",
    "                board[i][j] = ' '\n",
    "                if move_val < best_val:\n",
    "                    best_val = move_val\n",
    "                    best_move = (i, j)\n",
    "    return best_move\n",
    "\n",
    "def is_valid_move(board, row, col):\n",
    "    return (0 <= row < len(board)) and (0 <= col < len(board[row])) and board[row][col] == ' '\n",
    "\n",
    "def main():\n",
    "    board = [[' ']*4, [' ']*3, [' ']*3]\n",
    "\n",
    "    print(\"You are X. Computer is O.\")\n",
    "    print(\"Computer plays first!\")\n",
    "\n",
    "    while True:\n",
    "        move = find_best_move(board)\n",
    "        if move != (-1, -1):\n",
    "            board[move[0]][move[1]] = 'O'\n",
    "        print_board(board)\n",
    "\n",
    "        if evaluate(board) == 1:\n",
    "            print(\"Computer wins! (should not happen)\")\n",
    "            break\n",
    "        if not is_moves_left(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                r, c = map(int, input(\"Enter your move (row col): \").split())\n",
    "                if is_valid_move(board, r, c):\n",
    "                    board[r][c] = 'X'\n",
    "                    break\n",
    "                print(\"Invalid move. Try again.\")\n",
    "            except:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "\n",
    "        print_board(board)\n",
    "\n",
    "        if evaluate(board) == -1:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "        if not is_moves_left(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95bfe66",
   "metadata": {},
   "source": [
    "17. Implement a simple ***Multi-Layer Perceptron with N binary inputs, two hidden layers and one binary output***. Display the final weight matrices, bias values and the number of steps. Note that random values are assigned to weight matrices and bias in each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bin_step(x):\n",
    "    return np.where(x>=0,1,0)\n",
    "\n",
    "def forward(x,w1,b1,w2,b2,w3,b3):\n",
    "    h1=bin_step(np.dot(x,w1)+b1)\n",
    "    h2=bin_step(np.dot(h1,w2)+b2)\n",
    "    op=bin_step(np.dot(h2,w3)+b3)\n",
    "    return h1,h2,op\n",
    "\n",
    "N = int(input(\"Enter number of binary inputs: \"))\n",
    "X = np.random.randint(0, 2, N)  # Generate random binary inputs\n",
    "steps = 0\n",
    "\n",
    "while True:\n",
    "    steps+=1\n",
    "    w1=np.random.randn(N,5)\n",
    "    b1=np.random.randn(5)\n",
    "    w2=np.random.randn(5,3)\n",
    "    b2=np.random.randn(3)\n",
    "    w3=np.random.randn(3,1)\n",
    "    b3=np.random.randn(1)\n",
    "    h1,h2,y = forward(X,w1,b1,w2,b2,w3,b3)\n",
    "    \n",
    "    if y ==1:\n",
    "        break\n",
    "\n",
    "print(\"\\nFinal Output:\")\n",
    "print(\"Input:\", X)\n",
    "print(\"Hidden Layer 1 Output:\", h1)\n",
    "print(\"Hidden Layer 2 Output:\", h2)\n",
    "print(\"Final Output (Y):\", y)\n",
    "\n",
    "print(\"\\nFinal Weights and Biases:\")\n",
    "print(\"W1:\\n\", w1)\n",
    "print(\"B1:\", b1)\n",
    "print(\"W2:\\n\", w2)\n",
    "print(\"B2:\", b2)\n",
    "print(\"W3:\\n\", w3)\n",
    "print(\"B3:\", b3)\n",
    "print(\"Steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45afaa",
   "metadata": {},
   "source": [
    "18. Implement a simple Multi-Layer Perceptron with 4 binary inputs, one hidden layer and two binary outputs. Display the final weight matrices, bias values and the number of steps. Note that random values are assigned to\n",
    "weight matrices and bias in each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bin_step(x):\n",
    "    return np.where(x>=0,1,0)\n",
    "\n",
    "def forward(x,w1,b1,w2,b2,w3,b3):\n",
    "    h1=bin_step(np.dot(x,w1)+b1)\n",
    "    h2=bin_step(np.dot(h1,w2)+b2)\n",
    "    op=bin_step(np.dot(h2,w3)+b3)\n",
    "    return h1,h2,op\n",
    "\n",
    "N = 4\n",
    "X = np.random.randint(0, 2, N)  # Generate random binary inputs\n",
    "steps = 0\n",
    "\n",
    "while True:\n",
    "    steps+=1\n",
    "    w1=np.random.randn(N,5)\n",
    "    b1=np.random.randn(5)\n",
    "    w2=np.random.randn(5,3)\n",
    "    b2=np.random.randn(3)\n",
    "    w3=np.random.randn(3,1)\n",
    "    b3=np.random.randn(1)\n",
    "    h1,h2,y = forward(X,w1,b1,w2,b2,w3,b3)\n",
    "    \n",
    "    if y ==1:\n",
    "        break\n",
    "\n",
    "print(\"\\nFinal Output:\")\n",
    "print(\"Input:\", X)\n",
    "print(\"Hidden Layer 1 Output:\", h1)\n",
    "print(\"Hidden Layer 2 Output:\", h2)\n",
    "print(\"Final Output (Y):\", y)\n",
    "\n",
    "print(\"\\nFinal Weights and Biases:\")\n",
    "print(\"W1:\\n\", w1)\n",
    "print(\"B1:\", b1)\n",
    "print(\"W2:\\n\", w2)\n",
    "print(\"B2:\", b2)\n",
    "print(\"W3:\\n\", w3)\n",
    "print(\"B3:\", b3)\n",
    "print(\"Steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61b97d",
   "metadata": {},
   "source": [
    "19. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and Sigmoid function as an activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def sigmoid_der(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "n = int(input(\"Enter number of binary inputs: \"))\n",
    "inputs = np.array([list(map(int, input(f\"Enter binary inputs {i+1}: \").split())) for i in range(2**n)])\n",
    "outputs = np.array([int(input(f\"Enter expected output for {list(i)}: \")) for i in inputs]).reshape(-1, 1)\n",
    "print(inputs)\n",
    "print(outputs)\n",
    "w1, b1 = np.random.randn(n, 4), np.random.randn(4)\n",
    "w2, b2 = np.random.randn(4, 3), np.random.randn(3)\n",
    "w3, b3 = np.random.randn(3, 1), np.random.randn(1)\n",
    "\n",
    "for _ in range(10000):\n",
    "    h1=sigmoid(np.dot(inputs,w1)+b1)\n",
    "    h2=sigmoid(np.dot(h1,w2)+b2)\n",
    "    output=sigmoid(np.dot(h2,w3)+b3)\n",
    "\n",
    "    error=outputs-output\n",
    "    w3+=np.dot(h2.T,error*sigmoid_der(output))\n",
    "    b3+=np.sum(error*sigmoid_der(output),axis=0)\n",
    "    w2+=np.dot(h1.T,(error.dot(w3.T)*sigmoid_der(h2)))\n",
    "    b2+=np.sum((error.dot(w3.T))*sigmoid_der(h2),axis=0)\n",
    "    w1+=np.dot(inputs.T,(error.dot(w3.T).dot(w2.T)*sigmoid_der(h1)))\n",
    "    b1+=np.sum((error.dot(w3.T).dot(w2.T))*sigmoid_der(h1),axis=0)\n",
    "\n",
    "print(\"Final Weights and Biases:\")\n",
    "print(\"w1:\", w1)\n",
    "print(\"b1:\", b1)\n",
    "print(\"w2:\", w2)\n",
    "print(\"b2:\", b2)\n",
    "print(\"w3:\", w3)\n",
    "print(\"b3:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec64208",
   "metadata": {},
   "source": [
    "20. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and ReLU function as activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aaa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def relu_d(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "n = int(input(\"Enter number of binary inputs: \"))\n",
    "inputs = np.array([list(map(int, input(f\"Enter binary inputs {i+1}: \").split())) for i in range(2**n)])\n",
    "outputs = np.array([int(input(f\"Enter expected output for {list(i)}: \")) for i in inputs]).reshape(-1, 1)\n",
    "\n",
    "w1, b1 = np.random.randn(n, 4), np.random.randn(4)\n",
    "w2, b2 = np.random.randn(4, 3), np.random.randn(3)\n",
    "w3, b3 = np.random.randn(3, 1), np.random.randn(1)\n",
    "\n",
    "for _ in range(10000):\n",
    "    h1=relu(np.dot(inputs,w1)+b1)\n",
    "    h2=relu(np.dot(h1,w2)+b2)\n",
    "    output=relu(np.dot(h2,w3)+b3)\n",
    "\n",
    "    error=outputs-output\n",
    "    w3+=np.dot(h2.T,error*relu_d(output))\n",
    "    b3+=np.sum(error*relu_d(output),axis=0)\n",
    "    w2+=np.dot(h1.T,(error.dot(w3.T)*relu_d(h2)))\n",
    "    b2+=np.sum((error.dot(w3.T))*relu_d(h2),axis=0)\n",
    "    w1+=np.dot(inputs.T,(error.dot(w3.T).dot(w2.T)*relu_d(h1)))\n",
    "    b1+=np.sum((error.dot(w3.T).dot(w2.T))*relu_d(h1),axis=0)\n",
    "\n",
    "print(\"Final Weights and Biases:\")\n",
    "print(\"w1:\", w1)\n",
    "print(\"b1:\", b1)\n",
    "print(\"w2:\", w2)\n",
    "print(\"b2:\", b2)\n",
    "print(\"w3:\", w3)\n",
    "print(\"b3:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e39325",
   "metadata": {},
   "source": [
    "21. Implement a simple Multi-Layer Perceptron with N binary inputs, two hidden layers and one output. Use backpropagation and Tanh function as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_d(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "n = int(input(\"Enter number of binary inputs: \"))\n",
    "inputs = np.array([list(map(int, input(f\"Enter binary inputs {i+1}: \").split())) for i in range(2**n)]).reshape(-1, n)\n",
    "outputs = np.array([int(input(f\"Enter expected output for {list(i)}: \")) for i in inputs]).reshape(-1, 1)\n",
    "\n",
    "w1, b1 = np.random.randn(inputs.shape[1], 4), np.random.randn(4)\n",
    "w2, b2 = np.random.randn(4, 3), np.random.randn(3)\n",
    "w3, b3 = np.random.randn(3, 1), np.random.randn(1)\n",
    "\n",
    "for _ in range(10000):\n",
    "    h1=tanh(np.dot(inputs,w1)+b1)\n",
    "    h2=tanh(np.dot(h1,w2)+b2)\n",
    "    output=tanh(np.dot(h2,w3)+b3)\n",
    "\n",
    "    error=outputs-output\n",
    "    w3+=np.dot(h2.T,error*tanh_d(output))\n",
    "    b3+=np.sum(error*tanh_d(output),axis=0)\n",
    "    w2+=np.dot(h1.T,(error.dot(w3.T)*tanh_d(h2)))\n",
    "    b2+=np.sum((error.dot(w3.T))*tanh_d(h2),axis=0)\n",
    "    w1+=np.dot(inputs.T,(error.dot(w3.T).dot(w2.T)*tanh_d(h1)))\n",
    "    b1+=np.sum((error.dot(w3.T).dot(w2.T))*tanh_d(h1),axis=0)\n",
    "\n",
    "print(\"Final Weights and Biases:\")\n",
    "print(\"w1:\", w1)\n",
    "print(\"b1:\", b1)\n",
    "print(\"w2:\", w2)\n",
    "print(\"b2:\", b2)\n",
    "print(\"w3:\", w3)\n",
    "print(\"b3:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46505a7",
   "metadata": {},
   "source": [
    "22. Write a program to read a text file with at least 30 sentences and 200 words\n",
    "and perform the following tasks in the given sequence.\n",
    "    a. Text cleaning by removing punctuation/special characters, numbers and extra white spaces. Use regular expressions for the same.\n",
    "    b. Convert text to lowercase\n",
    "    c. Tokenization\n",
    "    d. Remove stop words\n",
    "    e. Correct misspelled words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# Download resources if they are not already installed\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "with open('sample.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Clean the text\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
    "text = re.sub(r'\\s+', ' ', text).strip()  # Replace extra spaces\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "tokens = text.split()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Correct spelling using TextBlob\n",
    "corrected_tokens = [str(TextBlob(word).correct()) for word in tokens]\n",
    "\n",
    "print(corrected_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c39a9",
   "metadata": {},
   "source": [
    "23. Write a program to read a text file with at least 30 sentences and 200 words\n",
    "and perform the following tasks in the given sequence.\n",
    "    a. Text cleaning by removing punctuation/special characters, numbers\n",
    "    and extra white spaces. Use regular expressions for the same.\n",
    "    b. Convert text to lowercase\n",
    "    c. Stemming and Lemmatization\n",
    "    d. Create a list of 3 consecutive words after lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "with open('sample.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Clean the text\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
    "text = re.sub(r'\\s+', ' ', text).strip()  # Replace extra spaces\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "tokens = text.split()\n",
    "\n",
    "stemmed = [PorterStemmer().stem(word) for word in tokens]\n",
    "lemmatized = [WordNetLemmatizer().lemmatize(word) for word in tokens]\n",
    "\n",
    "# 3 consecutive words after lemmatization\n",
    "consecutive = [lemmatized[i:i+3] for i in range(len(lemmatized)-2)]\n",
    "\n",
    "# Output first 10 results\n",
    "print(\"Stemming & Lemmatization Example:\")\n",
    "for i in range(min(10, len(tokens))):\n",
    "    print(f\"{tokens[i]} -> {stemmed[i]} -> {lemmatized[i]}\")\n",
    "\n",
    "print(\"\\nConsecutive Words (Lemmatized):\")\n",
    "for i in range(min(10, len(consecutive))):\n",
    "    print(f\"{i+1}: {' '.join(consecutive[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61774d9",
   "metadata": {},
   "source": [
    "24. Write a program to read a 3 text files on any technical concept with at least\n",
    "20 sentences and 150 words. Implement one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06422da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access          according       across          address         ai              aims            alexa           algorithms      also            amazon          an              analytics       and             another         anyone          application     applications    are             artificial      as              assistants      automatically   autonomous      avoid           aws             azure           backup          based           be              become          benefit         benefits        beyond          bias            bitcoin         block           blockchain      blockchains     blocks          both            business        by              can             carries         categorized     certain         certifications  chain           challenges      chatbots        cheaper         cloud           clouds          common          companies       compliance      compose         computers       computing       concern         conditions      connected       consensus       considered      consumption     contains        continues       contracts       control         core            correction      costs           could           critical        cryptocurrency  cryptographic   customer        data            databases       decentralized   decisions       deep            delivers        demand          deployment      designed        detection       development     diagnosis       digital         disaster        down            each            edge            eliminates      emerging        empowered       enables         encryption      energy          ensures         ethereum        ethics          even            evolve          execute         expense         expert          explainable     exploring       faster          field           first           flexibility     for             fraud           from            fungible        future          google          growing         hardware        has             hash            healthcare      heavily         help            holds           human           hybrid          iaas            image           important       improve         in              include         industries      innovation      intelligence    intermediaries  internet        introduced      investments     involves        is              it              language        layers          lead            learning        ledger          level           like            links           lock            machine         machines        major           make            management      many            mechanisms      met             model           models          more            multi           music           natural         navigation      necessary       need            needs           netflix         networking      networks        neural          new             nfts            non             of              offer           offers          often           on              online          open            or              organizations   out             outcomes        over            owning          paas            paint           part            patient         potential       previous        private         processes       processing      programs        promise         proof           protection      provide         providers       provides        public          quickly         rapid           rapidly         reasoning       recent          recognition     recommendation  recommendations records         recovery        reduced         regulatory      rely            remote          require         research        reshaping       resources       restricted      robotics        run             saas            scalability     scalable        scale           secure          securely        security        see             self            serverless      servers         service         services        simpler         simulation      siri            smart           software        specific        stake           storage         strategies      strong          subset          supply          supports        systems         task            tasks           technology      that            the             they            this            through         to              tokens          tools           transactions    transparency    treatment       trust           understandable  unfair          up              use             used            users           uses            using           vehicles        vendor          via             virtualized     voice           voting          was             weak            when            widely          will            with            work           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0               0               0               0               1               1               1               1               1               1               1               0               1               1               0               0               1               1               1               1               1               0               1               0               0               0               0               0               1               0               0               0               0               1               0               0               0               0               0               1               0               1               1               1               1               0               0               0               1               1               0               0               0               0               0               0               1               0               0               1               0               0               0               1               0               0               0               0               1               1               1               0               0               0               0               0               1               0               0               0               1               1               0               0               0               1               1               0               1               0               0               0               0               0               0               1               1               0               0               0               0               0               1               0               0               0               0               1               1               0               0               1               0               0               1               1               0               0               1               0               1               0               0               0               1               1               0               1               1               0               0               1               0               0               1               1               1               0               1               0               0               0               1               1               1               1               1               1               1               1               0               1               1               0               0               1               1               0               1               0               1               0               0               0               1               1               0               1               1               1               0               0               0               1               0               1               1               0               0               0               1               0               0               0               1               0               0               1               0               1               1               0               0               0               1               1               0               0               0               0               1               1               0               1               0               0               1               0               0               0               0               0               1               1               0               1               1               1               0               0               0               0               1               0               1               1               1               0               0               1               0               0               0               0               0               0               0               0               0               1               0               0               1               0               0               1               1               0               0               1               0               0               0               1               1               0               0               1               1               1               0               0               1               0               0               0               1               0               0               0               0               1               0               1               1               0               1               1               0               1               1               1               0               0               0               1               0               0               1               0               0               0               1               0              \n",
      "1               1               0               0               0               0               0               0               0               0               0               1               1               0               0               0               0               1               0               0               0               0               0               1               1               1               1               0               0               1               1               0               0               0               0               0               0               0               0               0               1               0               1               0               0               0               1               0               0               0               0               1               1               1               1               1               0               0               1               1               0               1               0               0               0               0               0               0               1               0               0               1               0               1               0               0               0               1               1               0               0               0               1               1               1               0               0               1               0               0               1               1               0               1               0               1               0               1               1               0               0               0               0               1               0               0               1               0               0               0               0               0               0               1               1               0               1               0               1               1               0               1               0               0               0               0               1               0               0               1               1               0               0               0               1               1               0               1               0               0               1               0               0               0               1               1               0               0               0               0               0               0               0               0               1               0               0               1               0               0               0               0               0               1               1               1               1               0               0               0               1               0               1               0               1               0               0               1               0               0               1               1               1               1               1               1               0               1               1               0               0               1               1               1               0               0               0               0               0               1               0               0               0               0               0               1               0               1               1               1               1               1               0               0               0               0               0               0               0               1               1               0               0               1               0               0               0               1               0               0               0               1               0               1               1               0               0               1               1               0               1               1               1               1               1               0               0               0               1               0               0               1               1               0               0               0               1               0               0               0               0               0               1               1               0               1               1               0               1               0               0               0               0               0               0               1               0               0               0               0               0               0               1               1               1               0               0               0               0               0               0               1               1               1              \n",
      "0               0               1               1               0               0               0               0               0               0               0               0               1               0               1               1               1               1               0               0               0               1               0               0               0               0               0               1               0               0               0               1               1               0               1               1               1               1               1               0               0               0               1               0               0               1               0               1               1               0               1               0               0               0               0               0               0               1               0               0               1               0               1               0               1               1               1               1               0               0               0               0               1               0               1               1               0               0               0               1               0               0               0               0               0               0               0               0               0               1               0               0               1               0               1               0               0               0               0               1               1               1               0               0               1               1               0               0               0               1               1               0               1               0               1               0               1               1               0               0               0               0               1               1               1               0               0               0               0               0               0               0               1               1               0               1               1               1               0               1               0               1               0               0               1               1               0               0               0               0               1               0               0               1               0               0               0               0               0               1               1               1               1               0               0               0               0               0               0               0               0               1               0               0               0               0               0               0               1               1               1               0               1               0               1               0               1               1               0               0               0               0               0               0               0               0               1               1               1               1               0               0               1               0               1               0               0               0               0               1               0               0               1               0               1               0               0               0               1               0               0               1               0               0               0               0               0               0               1               0               1               0               1               0               0               1               1               1               0               0               0               0               0               0               0               0               0               1               0               0               1               0               0               0               0               1               0               1               0               0               1               1               1               1               1               0               1               1               0               1               1               0               1               0               0               0               1               0               1               0               0               0               0               0               0               0               1               1               0               1               1               0               0               1              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "def one_hot(texts):\n",
    "    vect=CountVectorizer(binary=True)\n",
    "    return vect.fit_transform(texts).toarray(),vect.get_feature_names_out()\n",
    "\n",
    "def display(matrix,feat):\n",
    "    print(*[f\"{w:<15}\" for w in feat])\n",
    "    print(\"-\" * len(feat) * 15)\n",
    "    for row in matrix:\n",
    "        print(\" \".join([f\"{int(val):<15}\" for val in row]))\n",
    "\n",
    "files = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]\n",
    "texts = [open(file, 'r', encoding='utf-8').read() for file in files]\n",
    "matrix,feat=one_hot(texts)\n",
    "display(matrix,feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d5872",
   "metadata": {},
   "source": [
    "25. Write a program to read a 3 text files on a movie review with at least 20 sentences and 150 words. Implement bag of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0700f763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['absolutely' 'acting' 'action' 'actionpacked' 'actor' 'add' 'added'\n",
      " 'avoid' 'awards' 'away' 'background' 'balance' 'bit' 'breaking' 'cast'\n",
      " 'certainly' 'characters' 'charming' 'cinematography' 'citys' 'cliches'\n",
      " 'coaster' 'complemented' 'complete' 'credits' 'delivered' 'depth'\n",
      " 'design' 'didnt' 'direction' 'disaster' 'dragging' 'drama' 'edge'\n",
      " 'effects' 'emotional' 'ended' 'enjoyable' 'entertaining' 'entertainment'\n",
      " 'entire' 'especially' 'execution' 'expected' 'expecting' 'family'\n",
      " 'fantastic' 'fast' 'feelgood' 'felt' 'film' 'films' 'finish' 'fits'\n",
      " 'follow' 'forced' 'given' 'good' 'gripping' 'hard' 'highly' 'hooked'\n",
      " 'humor' 'hype' 'involving' 'just' 'kept' 'key' 'lacked' 'lead' 'letdown'\n",
      " 'lightheartedness' 'long' 'looking' 'loves' 'moments' 'mood' 'movie'\n",
      " 'movies' 'music' 'natural' 'original' 'outstanding' 'overall'\n",
      " 'overshadowed' 'overthetop' 'pacing' 'particularly' 'perfectly'\n",
      " 'performance' 'performances' 'pick' 'place' 'pleasantly' 'plot' 'poor'\n",
      " 'poorly' 'predictable' 'rare' 'real' 'recommend' 'refreshing' 'ride'\n",
      " 'right' 'roll' 'roller' 'rushed' 'scenes' 'score' 'seat' 'skyline' 'slow'\n",
      " 'solid' 'sound' 'soundtrack' 'start' 'stays' 'stellar' 'storyline'\n",
      " 'stunning' 'surprised' 'thrillers' 'thrilling' 'time' 'times' 'topnotch'\n",
      " 'twists' 'typical' 'uneven' 'unexpected' 'unique' 'value' 'visual'\n",
      " 'visually' 'wasnt' 'waste' 'watch' 'welldeveloped' 'win' 'worth'\n",
      " 'wouldnt' 'yawning' 'youre']\n",
      "Bag of Words Matrix:\n",
      "[1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 1 0 0 3 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 1 0 0 1 2 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0\n",
      " 2 1 1 0 1 0 0 1 1 0 0 1 1 3 0 0 0 0 0 0 2 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
      " 0 2 0 2 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 3 1 1 1 0 0 1]\n",
      "[0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 2 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1\n",
      " 0 1 1 3 0 1 0 0 0 1 1 1 1 0 0 0 0 0 2 0 1 1 1 0 0 1 1 0 0 0 0 0 1 2 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def read_files(file_paths):\n",
    "    \"\"\"Read content from multiple files\"\"\"\n",
    "    return [open(file, 'r', encoding='utf-8').read() for file in file_paths]\n",
    "\n",
    "def preprocess_text(text_data):\n",
    "    \"\"\"Preprocess text (remove punctuation and convert to lowercase)\"\"\"\n",
    "    return [re.sub(r'[^\\w\\s]', '', text.lower()) for text in text_data]\n",
    "\n",
    "def bag_of_words(text_data):\n",
    "    \"\"\"Generate Bag of Words representation\"\"\"\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(text_data)\n",
    "    return vectorizer.get_feature_names_out(), X.toarray()\n",
    "\n",
    "def display_bag_of_words(feature_names, bow_matrix):\n",
    "    \"\"\"Display Bag of Words matrix\"\"\"\n",
    "    print(\"Feature Names:\", feature_names)\n",
    "    print(\"Bag of Words Matrix:\")\n",
    "    for row in bow_matrix:\n",
    "        print(row)\n",
    "\n",
    "def analyze_movie_reviews(file_paths):\n",
    "    text_data = preprocess_text(read_files(file_paths))\n",
    "    feature_names, bow_matrix = bag_of_words(text_data)\n",
    "    display_bag_of_words(feature_names, bow_matrix)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\"movie_review1.txt\", \"movie_review2.txt\", \"movie_review3.txt\"]\n",
    "    analyze_movie_reviews(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77c551",
   "metadata": {},
   "source": [
    "26. Write a program to read a 3 text files about a tourist place with at least 20 sentences and 150 words. Implement TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44a4abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF Values ---\n",
      "\n",
      "Document 1:\n",
      "10: 0.13095288820759474\n",
      "100: 0.13095288820759474\n",
      "1889: 0.13095288820759474\n",
      "330: 0.13095288820759474\n",
      "breathtaking: 0.13095288820759474\n",
      "city: 0.09959304685191944\n",
      "creating: 0.13095288820759474\n",
      "criticized: 0.13095288820759474\n",
      "designed: 0.13095288820759474\n",
      "eiffel: 0.3928586646227842\n",
      "elevator: 0.13095288820759474\n",
      "enjoy: 0.13095288820759474\n",
      "evening: 0.13095288820759474\n",
      "fair: 0.13095288820759474\n",
      "famous: 0.09959304685191944\n",
      "floor: 0.13095288820759474\n",
      "france: 0.13095288820759474\n",
      "gustave: 0.13095288820759474\n",
      "illuminated: 0.13095288820759474\n",
      "initially: 0.13095288820759474\n",
      "iron: 0.13095288820759474\n",
      "landmarks: 0.13095288820759474\n",
      "magical: 0.13095288820759474\n",
      "meters: 0.13095288820759474\n",
      "offers: 0.13095288820759474\n",
      "originally: 0.13095288820759474\n",
      "paris: 0.13095288820759474\n",
      "ride: 0.13095288820759474\n",
      "second: 0.13095288820759474\n",
      "sight: 0.13095288820759474\n",
      "soon: 0.13095288820759474\n",
      "standing: 0.13095288820759474\n",
      "symbol: 0.13095288820759474\n",
      "tall: 0.13095288820759474\n",
      "tons: 0.13095288820759474\n",
      "tower: 0.3928586646227842\n",
      "view: 0.2619057764151895\n",
      "visitors: 0.09959304685191944\n",
      "weighs: 0.13095288820759474\n",
      "world: 0.09959304685191944\n",
      "wrought: 0.13095288820759474\n",
      "\n",
      "Document 2:\n",
      "000: 0.1444266677300618\n",
      "21: 0.1444266677300618\n",
      "architectural: 0.1444266677300618\n",
      "built: 0.10984020347152938\n",
      "centuries: 0.1444266677300618\n",
      "china: 0.1444266677300618\n",
      "chinese: 0.1444266677300618\n",
      "constructed: 0.1444266677300618\n",
      "deserts: 0.1444266677300618\n",
      "destinations: 0.1444266677300618\n",
      "feats: 0.1444266677300618\n",
      "fortifications: 0.1444266677300618\n",
      "great: 0.1444266677300618\n",
      "greatest: 0.1444266677300618\n",
      "heritage: 0.1444266677300618\n",
      "including: 0.1444266677300618\n",
      "invasions: 0.1444266677300618\n",
      "kilometers: 0.1444266677300618\n",
      "mountains: 0.10984020347152938\n",
      "protect: 0.1444266677300618\n",
      "rugged: 0.1444266677300618\n",
      "runs: 0.1444266677300618\n",
      "series: 0.1444266677300618\n",
      "single: 0.1444266677300618\n",
      "site: 0.10984020347152938\n",
      "stands: 0.1444266677300618\n",
      "states: 0.1444266677300618\n",
      "stretching: 0.1444266677300618\n",
      "terrain: 0.1444266677300618\n",
      "today: 0.1444266677300618\n",
      "tourist: 0.1444266677300618\n",
      "unesco: 0.1444266677300618\n",
      "visited: 0.1444266677300618\n",
      "wall: 0.4332800031901854\n",
      "walls: 0.1444266677300618\n",
      "watchtowers: 0.1444266677300618\n",
      "world: 0.32952061041458813\n",
      "\n",
      "Document 3:\n",
      "15th: 0.14402944119273375\n",
      "1911: 0.14402944119273375\n",
      "abandoned: 0.14402944119273375\n",
      "adventure: 0.14402944119273375\n",
      "american: 0.14402944119273375\n",
      "ancient: 0.14402944119273375\n",
      "andes: 0.14402944119273375\n",
      "bingham: 0.14402944119273375\n",
      "built: 0.10953810245119737\n",
      "century: 0.14402944119273375\n",
      "city: 0.10953810245119737\n",
      "construction: 0.14402944119273375\n",
      "destination: 0.14402944119273375\n",
      "dry: 0.14402944119273375\n",
      "estate: 0.14402944119273375\n",
      "famous: 0.10953810245119737\n",
      "hike: 0.14402944119273375\n",
      "hiram: 0.14402944119273375\n",
      "historian: 0.14402944119273375\n",
      "inca: 0.2880588823854675\n",
      "later: 0.14402944119273375\n",
      "located: 0.14402944119273375\n",
      "machu: 0.2880588823854675\n",
      "making: 0.14402944119273375\n",
      "mountains: 0.10953810245119737\n",
      "panoramic: 0.14402944119273375\n",
      "peru: 0.14402944119273375\n",
      "picchu: 0.2880588823854675\n",
      "popular: 0.14402944119273375\n",
      "reach: 0.14402944119273375\n",
      "rediscovered: 0.14402944119273375\n",
      "religious: 0.14402944119273375\n",
      "royal: 0.14402944119273375\n",
      "site: 0.21907620490239474\n",
      "sophisticated: 0.14402944119273375\n",
      "stone: 0.14402944119273375\n",
      "thought: 0.14402944119273375\n",
      "trail: 0.14402944119273375\n",
      "views: 0.14402944119273375\n",
      "visitors: 0.10953810245119737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Read files into a list\n",
    "file_paths = [\"tourist_place1.txt\", \"tourist_place2.txt\", \"tourist_place3.txt\"]\n",
    "texts = [open(file, 'r', encoding='utf-8').read() for file in file_paths]\n",
    "\n",
    "# Calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Display TF-IDF results\n",
    "print(\"\\n--- TF-IDF Values ---\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i in range(tfidf_matrix.shape[0]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    for j in range(tfidf_matrix.shape[1]):\n",
    "        if tfidf_matrix[i, j] > 0:\n",
    "            print(f\"{feature_names[j]}: {tfidf_matrix[i, j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
